# 本地化Prompt评测平台

## 1. 概述

### 1.1 产品描述
**本地化Prompt评测平台**用于试验各种prompt版本，并通过集成LLM模型进行翻译，评估质量。平台集成prompt编辑/版本控制、LLM调用、自动化与人工评估以及动态Style Guide集成。

### 1.2 目标
- **Prompt试验与管理：**
  - 允许用户创建、编辑Prompt，并在每次编辑时自动生成新版本，记录修改时间及变更日志。
  - 为每个项目和语言组合维护详细的版本历史。
- **LLM翻译评估：**
  - 集成 AWS Bedrock 或其他模型SDK，执行翻译任务。
  - 提供整体和按segment的翻译质量评估，结合自动化指标（如 BLEU 分数）和人工评分（包括注释）。
- **动态Style Guide集成：**
  - 允许用户上传包含角色属性的 Excel Style Guide（如中文名称、性别、说话风格等）。
  - 在上传的测试文本中，系统自动匹配 “Extra” 列中的数据，并将prompt中的标记（如 `{name}`、`{gender}`）替换为Style Guide中对应的值。
- **协作与组织：**
  - 按项目和语言分类组织评测，每个项目-语言组合作为独立评测空间。
  - 支持多用户同时操作，每个用户可专注于自己负责的语言。
- **本地原型开发：**
  - 初期在本地环境部署，便于快速原型开发和内部测试，后续可扩展至云端托管。

## 2. 范围

### 2.1 功能需求

#### 2.1.1 Prompt管理与版本控制
- **Prompt编辑器：**
  - 提供富文本编辑器，支持语法高亮。
  - 针对特定项目-语言组合的Prompt编辑自动生成新版本。
- **版本控制：**
  - 每次编辑记录时间戳、变更日志及唯一版本 ID。
  - 用户可以查看版本历史、进行差异对比（Diff View）以及回滚至之前版本。

#### 2.1.2 项目与语言
- **预定义项目与语言：**
  - 平台界面允许用户选择预设的项目及对应语言。
- **用户专注：**
  - 虽然支持多用户操作，每个用户主要负责一个语言，系统支持团队协作。

#### 2.1.3 LLM集成
- **模型调用：**
  - 集成 AWS Bedrock 或其他模型的SDK来翻译。（AWS先集成）
  - 允许用户在每次调用时配置模型参数（如temperature、最大token数）。
- **调用流程：**
  - 支持异步 API 调用，并展示调用进度。
  - 记录所有 API 请求和响应log。

#### 2.1.4 评估模块
- **自动化评估：**
  - 系统自动计算翻译质量指标（编辑距离、BLEU分数或其他自定义指标）。
- **人工评估：**
  - 提供GUI供用户对整体及各segment翻译进行评分和注释，形成综合评估反馈。
- **结果对比：**
  - 展示不同Prompt版本翻译结果的并列对比，方便用户做出优化决策。

#### 2.1.5 Style Guide集成
- **Style Guide上传：**
  - 允许按照项目-语言的颗粒度提供Style Guide管理功能。
- **Extra数据上传：**
  - 允许用户上传包含 “Extra” 列的评测文件。
- **数据匹配与替换：**
  - 自动扫描 “Extra” 列，匹配Style Guide中的中文名称。
  - 将prompt中的标记（如 `{name}`、`{gender}`）替换为Style Guide中对应的属性值。

#### 2.1.6 数据持久化与分析
- **数据库存储：**
  - 使用数据库存储用户数据、项目与语言信息、prompt（含版本历史）、试验运行记录、LLM输出、评估结果以及Style Guide数据。
- **数据分析：**
  - 提供可视化仪表板，展示翻译质量趋势、版本表现及用户反馈，支持数据筛选和导出。

#### 2.1.7 用户管理（简化版）
- **角色权限：**
  - 支持管理员、评估者和观察者角色，确保用户权限明确。
- **认证机制：**
  - 内部使用的基础认证，可在未来扩展支持 SSO 等高级认证方案。

### 2.2 非功能性需求
- **可用性与用户体验：**
  - 界面设计简洁直观，适合各类用户使用，即使无技术背景也能快速上手。
- **性能与扩展性：**
  - 初期在本地环境部署，确保 API 调用和文件上传响应迅速。
  - 架构设计支持未来迁移至云端托管。
- **可维护性：**
  - 模块化代码结构，前后端分离，便于后续开发和系统扩展。

## 3. 系统架构

### 3.1 高级架构概览
- **前端：**
  - **用户界面：** 包含prompt编辑器、评估面板、文件上传组件、项目与语言选择器、版本差异视图以及数据分析仪表板。
- **后端：**
  - **API 服务器：** 处理prompt管理、API 调用、评估数据和文件上传等功能。
  - **LLM集成模块：** 负责与 LLM SDK 接口通信，并支持异步调用及日志记录。
  - **文件处理模块：** 解析上传的 Excel 文件，提取Style Guide和额外数据。
- **数据库：**
  - **SQL：** 用于存储所有持久化数据，包括prompt、版本历史、评估结果、用户信息和Style Guide数据。

### 3.2 数据流与交互流程
1. **用户交互：**
   - 用户选择项目和语言，在富文本编辑器中编辑prompt，每次保存生成新版本。
2. **LLM调用：**
   - 平台处理当前prompt（包括动态样式替换）后，通过 API 调用发送至LLM SDK，记录翻译输出和错误日志。
3. **评估处理：**
   - 接收翻译结果后，系统计算自动化质量指标，并展示结果供用户进行人工评分和注释。
4. **Style Guide处理：**
   - 上传Style Guide后，系统解析并存储相关数据；当上传包含 “Extra” 列的评测文件时，自动匹配并替换prompt中的标记。
5. **数据分析：**
   - 汇总prompt版本、LLM输出及评估数据，生成可视化仪表板和报告，支持数据筛选和导出。

## 4. 详细需求规格

### 4.1 功能模块

#### 4.1.1 Prompt编辑器与版本控制
- **功能：**
  - 提供直观的文本编辑区域用于输入和修改promp。
  - 每次编辑自动生成新版本，记录时间戳、变更摘要及唯一版本 ID。
  - 支持版本对比（Diff View）和回滚功能。
- **数据存储：**
  - 数据库中存储每个项目-语言组合的prompt记录，包括prompt文本、版本号、时间戳及变更日志。

#### 4.1.2 试验与评估模块
- **LLM调用：**
  - 用户配置参数后触发 API 调用至LLM SDK，支持异步处理和进度显示。
- **自动化评估：**
  - 系统根据翻译结果计算质量指标（如 BLEU 分数）。
- **人工评估：**
  - 提供评估表单，允许用户对整体及分段翻译进行评分和添加详细注释。
- **结果对比：**
  - 并列展示同一项目-语言组合下不同prompt版本/模型的翻译输出。
- **数据存储：**
  - 数据库表记录试验运行详情，包括翻译输出、自动化指标、人工评分、注释、用户信息和时间戳。

#### 4.1.3 Style Guide集成模块
- **文件上传：**
  - 提供界面组件以上传包含角色属性的Style Guide文件及包含 “Extra” 列的评测文件。
- **数据解析：**
  - 解析 Excel 文件，提取Style Guide数据（中文名称、性别、说话风格等）。
- **动态替换：**
  - 扫描评测文件中 “Extra” 列的中文角色名称，与语言Style Guide匹配后，将对应语言的prompt中的标记（如 `{name}`、`{gender}`）替换为对应属性值。
- **数据存储：**
  - 将解析后的Style Guide数据存储在专用数据库表中，便于后续匹配和替换。

#### 4.1.4 数据分析与报告
- **仪表板：**
  - 提供图表和表格展示翻译质量趋势、prompt版本表现及用户评估结果。
- **数据筛选：**
  - 支持按项目、语言、prompt版本及评估指标进行数据筛选。
- **数据导出：**
  - 允许用户导出报告数据以便进一步分析。

#### 4.1.5 用户管理模块
- **角色与权限：**
  - 支持管理员、评估者和观察者角色，明确各自权限范围。
- **认证：**
  - 实现基本的用户认证机制，适用于内部团队使用，未来可扩展至 SSO 认证。

### 4.2 非功能性要求
- **性能：**
  - 保证本地部署环境中 API 调用和文件上传的低延迟和高响应速度。
- **扩展性：**
  - 模块化架构设计支持未来系统迁移至云端部署。
- **可维护性：**
  - 前后端模块分离、代码结构清晰，便于后续开发和维护。
- **文档：**
  - 提供全面的开发和用户文档，包括 API 说明、数据库模式和部署指导。

## 5. 技术架构

### 5.1 前端
- **组件：**
  - **prompt编辑器：** 提供文本编辑和版本控制功能。
  - **评估面板：** 包括整体与分段评估的输入区域（评分和注释）。
  - **文件上传组件：** 用于上传Style Guide和试验评测文件。
  - **项目/语言选择器：** 下拉菜单或标签页，支持项目与语言的切换。
  - **差异视图：** 用于展示prompt版本间的差异。
  - **分析仪表板：** 提供图表和表格展示翻译质量和prompt表现。
- **技术：** *待定*

### 5.2 后端（API 服务器）
- **框架：**
  - *待定*
- **模块：**
  - **prompt管理模块：** 处理prompt的创建、编辑、版本控制和数据存储。
  - **LLM集成模块：** 负责与LLM SDK交互，支持异步 API 调用及日志记录。
  - **评估模块：** 收集自动化评估指标和用户人工评分，整合评估结果。
  - **文件处理模块：** 解析上传的 Excel 文件，提取Style Guide和额外数据。
- **API 端点：**
  - 包括prompt保存与检索、触发LLM调用、文件上传和评估数据记录的接口。

### 5.3 数据库（感觉可用SQL？）
- **数据库模式：**
  - **用户表：** 存储用户 ID、角色和认证信息。
  - **项目表：** 存储项目名称及相关元数据。
  - **语言表：** 存储语言代码和名称。
  - **prompt表：** 存储prompt文本、版本号、项目-语言关联信息及版本日志。
  - **试验运行表：** 记录LLM输出、自动化指标、评估数据及时间戳。
  - **评估结果表：** 存储整体及片段评分、用户注释和相关元数据。
  - **Style Guide表：** 存储上传解析后的Style Guide数据（中文名称、性别、说话风格等）。

### 5.4 部署
- **本地部署：**
  - 初期在本地环境中部署和测试，便于快速原型开发。
  - 可选使用 Docker 进行容器化部署。
- **公开访问：**
  - 在测试阶段，可使用 ngrok 等工具将本地服务器暴露至公网供团队使用。
- **未来扩展：**
  - 架构设计支持后续平滑过渡至云端托管。

## 6. 里程碑与路线图

### 6.1 阶段 1：调研与原型开发
- 完成详细需求确认。
- 确认技术实现方案，包括前端组件、后端架构、数据库等。
- 构建基础的界面，并与初步 API 端点集成进行验证。

### 6.2 阶段 2：核心功能实现
- **prompt管理：**
  - 实现prompt编辑器、自动版本控制和差异视图。
- **LLM集成：**
  - 集成LLM SDK以进行翻译调用。
- **评估模块：**
  - 构建自动化评估与人工评分界面。
- **文件上传与处理：**
  - 实现Style Guide和试验数据文件上传组件。
  - 开发动态标记替换逻辑。

### 6.3 阶段 3：测试与迭代
- 进行单元测试和集成测试，确保各模块功能稳定。
- 收集团队反馈，优化用户体验和界面设计。
- 验证Style Guide匹配及prompt标记替换功能的准确性。

### 6.4 阶段 4：数据分析与报告
- 开发数据分析仪表板，实现翻译质量、版本表现和评估数据的可视化。
- 实现数据导出和筛选功能，支持后续数据分析需求。

### 6.5 阶段 5：最终审核与文档整理
- 完成内部开发文档和代码注释。
- 准备本地部署脚本和相关配置。
- 可选为更广泛的内部测试设置临时公开访问。
---